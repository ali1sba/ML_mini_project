{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81604de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/.~lock.train.csv#\n",
      "./dataset/raw_data.csv\n",
      "./dataset/sample_submission.csv\n",
      "./dataset/test.csv\n",
      "./dataset/train.csv\n",
      "./dataset/train_data_dict.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('./dataset/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1bc3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ce2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df      = pd.read_csv('./dataset/train.csv')\n",
    "train_desc_df = pd.read_csv('./dataset/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7313d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "df = df.drop(['case_id','patientid'],axis=1)\n",
    "df = df.dropna(axis=0)\n",
    "# spliting\n",
    "train_df , test_df  = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# conveting to list \n",
    "#data1 = train_df.values.tolist()\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0fff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the deffirant keys (columns names)\n",
    "keys = train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b140af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discritisation(listA , listB , n):\n",
    "    listt = []\n",
    "    for i in range(len(listA)):\n",
    "        listt.append((listA[i], listB[i]))\n",
    "    new_list = sorted(listt)\n",
    "    # Step-1 : Pre-division into as many intervals as there is a class change. Separator //\n",
    "    # Step-2 : If we have same value X in different intervals, we remove the separators between these intervals\n",
    "    # to have the values of X in the same interval\n",
    "    i=0\n",
    "    while i< len(new_list)-1 :\n",
    "        if new_list[i][1] != new_list[i+1][1]:\n",
    "            if new_list[i][0] != new_list[i+1][0]:\n",
    "                new_list.insert(i+1, '//')\n",
    "                i += 2\n",
    "            else :\n",
    "                i += 1\n",
    "        else :\n",
    "            i += 1\n",
    "    # Step-3 : Grouping of intervals such that there are at least n values of the same class in each interval\n",
    "    i = 0\n",
    "    class_cpt = {'0-10': 0,'11-20': 0,'21-30': 0,'31-40': 0,'41-50': 0,'51-60': 0,\n",
    "             '61-70': 0,'71-80': 0,'81-90': 0,'91-100': 0,'More than 100 Days': 0}\n",
    "    while i < len(new_list) - 1 :\n",
    "        while new_list[i] != '//' and i < len(new_list) - 1  :\n",
    "            class_cpt[new_list[i][1]] +=1\n",
    "            i += 1\n",
    "        flagN = 0\n",
    "        for valeur in class_cpt.values():\n",
    "            if valeur >= n :\n",
    "                flagN=1\n",
    "        if (not flagN):\n",
    "            new_list.pop(i)\n",
    "        else :\n",
    "            i += 1\n",
    "            class_cpt = {'0-10': 0,'11-20': 0,'21-30': 0,'31-40': 0,'41-50': 0,'51-60': 0,\n",
    "             '61-70': 0,'71-80': 0,'81-90': 0,'91-100': 0,'More than 100 Days': 0}\n",
    "     \n",
    "    # Step-4 : Grouping of adjacent intervals gaving the same majority clas\n",
    "    i = 0\n",
    "    posToDelete = 0\n",
    "    majClass0 = ''\n",
    "    majValue = 0\n",
    "    resultList = []\n",
    "    while i <= len(new_list) - 1 :\n",
    "        while new_list[i] != '//' and i < len(new_list) - 1 :\n",
    "            class_cpt[new_list[i][1]] +=1\n",
    "            i += 1\n",
    "        \n",
    "        max_value = max(class_cpt, key=class_cpt.get)\n",
    "        if majClass0 != max_value:\n",
    "            if majClass0 != '' :\n",
    "                mean = (new_list[posToDelete-1][0] + new_list[posToDelete+1][0]) / 2\n",
    "                resultList.append((mean,majClass0))\n",
    "            majClass0 = str(max_value)\n",
    "            posToDelete = i\n",
    "        else:\n",
    "            new_list.pop(posToDelete)\n",
    "            i -= 1\n",
    "            posToDelete = i\n",
    "        i += 1\n",
    "        \n",
    "    max_value = max(class_cpt, key=class_cpt.get)\n",
    "    if majClass0 != max_value:\n",
    "        if majClass0 != '' :\n",
    "            mean = (new_list[posToDelete-1][0] + new_list[posToDelete+1][0]) / 2\n",
    "            resultList.append((mean,majClass0))\n",
    "        majClass0 = str(max_value)\n",
    "        posToDelete = i\n",
    "    else:\n",
    "        new_list.pop(posToDelete)\n",
    "        i -= 1\n",
    "        posToDelete = i\n",
    "        resultList.append((new_list[posToDelete-1][0] ,majClass0))\n",
    "        \n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048e8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1803.5, '0-10'), (1844.0, 'More than 100 Days'), (2070.5, '0-10'), (2243.5, 'More than 100 Days'), (3262.5, '0-10'), (3265.5, '31-40'), (3266.5, '0-10'), (3267.5, '31-40'), (3268.5, '0-10'), (3270.5, '31-40'), (3272.5, '0-10'), (3734.5, '31-40'), (4631.5, '11-20'), (11008.0, '21-30')]\n"
     ]
    }
   ],
   "source": [
    "#test discritisation function\n",
    "result_of_desc=discritisation(train_df[keys[14]].values.tolist(),train_df[keys[-1]].values.tolist(),3)\n",
    "print(result_of_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "036adb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#application of the descritisation for dataset\n",
    "result_of_desc = []\n",
    "def application_of_desc_for_dataset(feature, n ):\n",
    "    result_of_desc = discritisation(train_df[feature].values.tolist(),train_df[keys[-1]].values.tolist(),n)\n",
    "    for i in train_df[keys[14]].keys().tolist():\n",
    "        flage = False\n",
    "        for j in result_of_desc:\n",
    "            if (j[0] >= train_df.loc[i,[feature]].item()):\n",
    "                train_df.loc[i,[feature]]=j[1]\n",
    "                flage = True\n",
    "                break\n",
    "        if(not flage):\n",
    "            train_df.loc[i,[feature]]= \"21-30\"\n",
    "        print(i)\n",
    "        #train_df.loc[i,[feature]]=value\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86af6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#application of the descritisation for value\n",
    "def application_of_desc_for_value(value):\n",
    "    flage = False\n",
    "    for j in result_of_desc:\n",
    "        if (j[0] >= value):\n",
    "            output=j[1]\n",
    "            flage = True\n",
    "            break\n",
    "    if(not flage):\n",
    "        output= \"21-30\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e22ab2",
   "metadata": {
    "tags": [
     "don't"
    ]
   },
   "outputs": [],
   "source": [
    "application_of_desc_for_dataset(keys[14],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aaf2570",
   "metadata": {
    "tags": [
     "don't"
    ]
   },
   "outputs": [],
   "source": [
    "# save data because time issue\n",
    "train_df.to_csv('raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40927f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting stay culumn from keys\n",
    "keys = train_df.columns.values.tolist()\n",
    "del keys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9603767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the freq of class values by eche feature value\n",
    "#Compter le nombre dâ€™apparences de chaque classe ğ¶k\n",
    "def getClassFreq(feature):\n",
    "    listOfDic=[]\n",
    "    tt = train_desc_df.filter(items=[feature, \"Stay\"])\n",
    "    tt.apply(pd.value_counts)\n",
    "    for i in tt.groupby(feature)['Stay'].apply(list).keys():\n",
    "        counts = Counter(tt.groupby(feature)['Stay'].apply(list)[i])\n",
    "        #print(counts)\n",
    "        dic = dict(counts)\n",
    "        sorted_dic = sorted(dic.items())\n",
    "        listOfDic.append((i,sorted_dic))\n",
    "    return listOfDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d90c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCFreq(feature):\n",
    "    listOfDic=[]\n",
    "    tt = train_desc_df.filter(items=[feature, \"Stay\"])\n",
    "    tt.apply(pd.value_counts)\n",
    "    for i in tt.groupby(feature)['Stay'].apply(list).keys():\n",
    "        counts = Counter(tt.groupby(feature)['Stay'].apply(list)[i])\n",
    "        #print(counts)\n",
    "        dic = dict(counts)\n",
    "        sorted_dic = sorted(dic.items())\n",
    "        attr=[o[1] for o in sorted_dic]\n",
    "        listOfDic.append(attr)\n",
    "    \n",
    "    return listOfDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293019f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the err local function\n",
    "def calculate_err_per_featuer(featuer):\n",
    "    result = getCFreq(featuer)\n",
    "    #print(result)\n",
    "    Sum = 0\n",
    "    for l in result:\n",
    "        Sum= sum(l)-max(l)\n",
    "    err = Sum/train_desc_df.shape[0]\n",
    "    print(\"Erreur Par Attribut \"+featuer+\": \" + str(err))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2218662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur Par Attribut Hospital_code: 0.026450600317088523\n",
      "Erreur Par Attribut Hospital_type_code: 0.009739716532421902\n",
      "Erreur Par Attribut City_Code_Hospital: 0.007815674370802361\n",
      "Erreur Par Attribut Hospital_region_code: 0.14305233554020572\n",
      "Erreur Par Attribut Available Extra Rooms in Hospital: 0.0\n",
      "Erreur Par Attribut Department: 0.002848219763059984\n",
      "Erreur Par Attribut Ward_Type: 2.3901144864839024e-05\n",
      "Erreur Par Attribut Ward_Facility_Code: 0.25277850809053753\n",
      "Erreur Par Attribut Bed Grade: 0.13008994797517467\n",
      "Erreur Par Attribut City_Code_Patient: 1.593409657655935e-05\n",
      "Erreur Par Attribut Type of Admission: 0.10968235378474629\n",
      "Erreur Par Attribut Severity of Illness: 0.3937793286965112\n",
      "Erreur Par Attribut Visitors with Patient: 0.0\n",
      "Erreur Par Attribut Age: 0.0031230829290056325\n",
      "Erreur Par Attribut Admission_Deposit: 0.000832556546125226\n"
     ]
    }
   ],
   "source": [
    "# Calculer lâ€™erreur de chaque attribut ğ´ğ´ğ‘–ğ‘– (âˆ‘ ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ ğ‘‰ğ‘‰ğ‘—ğ‘—)\n",
    "for i in keys:\n",
    "    calculate_err_per_featuer(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c82289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting over fitted features\n",
    "train_desc_df = train_desc_df.drop(['Available Extra Rooms in Hospital','Ward_Type','City_Code_Patient','Visitors with Patient'],axis=1)\n",
    "keys = train_desc_df.columns.values.tolist()\n",
    "del keys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed5a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur Par Attribut Hospital_code: 0.026450600317088523\n",
      "Erreur Par Attribut Hospital_type_code: 0.009739716532421902\n",
      "Erreur Par Attribut City_Code_Hospital: 0.007815674370802361\n",
      "Erreur Par Attribut Hospital_region_code: 0.14305233554020572\n",
      "Erreur Par Attribut Department: 0.002848219763059984\n",
      "Erreur Par Attribut Ward_Facility_Code: 0.25277850809053753\n",
      "Erreur Par Attribut Bed Grade: 0.13008994797517467\n",
      "Erreur Par Attribut Type of Admission: 0.10968235378474629\n",
      "Erreur Par Attribut Severity of Illness: 0.3937793286965112\n",
      "Erreur Par Attribut Age: 0.0031230829290056325\n",
      "Erreur Par Attribut Admission_Deposit: 0.000832556546125226\n",
      "__________________________________________________________\n",
      "the selected feature is Admission_Deposit\n"
     ]
    }
   ],
   "source": [
    "# Calculer lâ€™erreur de chaque attribut ğ´ğ´ğ‘–ğ‘– (âˆ‘ ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ ğ‘‰ğ‘‰ğ‘—ğ‘—)\n",
    "#SÃ©lectionner lâ€™attribut avec lâ€™erreur minimale\n",
    "listOfErr = []\n",
    "for i in keys:\n",
    "    listOfErr.append(calculate_err_per_featuer(i))\n",
    "print(\"__________________________________________________________\")\n",
    "print(\"the selected feature is \"+ keys[listOfErr.index(min(listOfErr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e7f3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construire la rÃ¨gle de dÃ©cision\n",
    "def prediction(value):\n",
    "    predictionV = \"21-30\"\n",
    "    tmp = application_of_desc_for_value(value)\n",
    "    for i in getClassFreq(\"Admission_Deposit\"):\n",
    "        if tmp == i[0]:\n",
    "            tmp = max(node[1] for node in i[1])\n",
    "            for j in i[1]:\n",
    "                if (j[1] == tmp):\n",
    "                    predictionV=j[0]\n",
    "    return predictionV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7f5cc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21-30'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(7441.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "852d5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 0.27527525932535574\n"
     ]
    }
   ],
   "source": [
    "#accuracy \n",
    "tmp=test_df.filter(items=[\"Admission_Deposit\", \"Stay\"]).values.tolist()\n",
    "#tmp=train_desc_df.filter(items=[\"Admission_Deposit\", \"Stay\"]).sample(n = 500).values.tolist()\n",
    "cptT = 0\n",
    "for i in tmp:\n",
    "    if (prediction(i[0])==i[1]):\n",
    "    #if (i[0]==i[1]):\n",
    "        cptT += 1 \n",
    "print(\"accuracy is : \" + str(cptT/len(test_df)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
